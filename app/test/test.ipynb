{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/10 22:27:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/10 22:27:44 WARN SparkEnv: I/O encryption enabled without RPC encryption: keys will be visible on the wire.\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init() \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"ETL pipeline\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"../spark-warehouse\")\\\n",
    "        .config('spark.driver.extraJavaOptions',f'-Dderby.system.home=../spark-warehouse/catalog')\\\n",
    "        .config(\"spark.io.encryption.enabled\",True)\\\n",
    "        .config('spark.acls.enable',True)\\\n",
    "        .enableHiveSupport().getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests to check if data & metadata stored correctly in storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/10 22:28:05 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "22/01/10 22:28:05 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "22/01/10 22:28:23 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "22/01/10 22:28:23 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore santiago@192.168.0.12\n",
      "22/01/10 22:28:24 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Table(name='restaurant', database='default', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## list of all tables stored in spark-warehouse \n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+-----------+--------------+------------+-------------+-------------------+-----------------+--------------+--------------+----------------+\n",
      "|                  id|          created_at|enabled|price_range|average_ticket|takeout_time|delivery_time|minimum_order_value|merchant_zip_code| merchant_city|merchant_state|merchant_country|\n",
      "+--------------------+--------------------+-------+-----------+--------------+------------+-------------+-------------------+-----------------+--------------+--------------+----------------+\n",
      "|02c94103-61f3-490...|2017-01-23 07:52:...|  false|          3|          60.0|           0|           50|               30.0|            14025|RIBEIRAO PRETO|            SP|              BR|\n",
      "|15e7f5fd-090d-47b...|2017-01-20 08:14:...|   true|          3|          60.0|           0|            0|               30.0|            50180|     SAO PAULO|            SP|              BR|\n",
      "|33ca5d3d-b99f-404...|2017-01-23 07:46:...|   true|          5|         100.0|           0|           45|               10.0|            23090|RIO DE JANEIRO|            RJ|              BR|\n",
      "|4927035f-a343-4a6...|2017-01-20 08:15:...|   true|          3|          80.0|           0|            0|               18.9|            40255|      SALVADOR|            BA|              BR|\n",
      "|52feaad8-4961-4af...|2017-01-20 08:14:...|   true|          3|          60.0|           0|            0|               25.0|            64600|       BARUERI|            SP|              BR|\n",
      "|539cb925-52ad-462...|2017-01-23 07:36:...|  false|          1|          30.0|           0|           60|               10.0|            18030|      SOROCABA|            SP|              BR|\n",
      "|5b6a43d0-8e25-4ad...|2017-01-23 07:40:...|  false|          1|          30.0|           0|           70|               11.0|            13208|       JUNDIAI|            SP|              BR|\n",
      "|7a6348e5-748c-4d3...|2017-01-20 08:14:...|   true|          4|          80.0|           0|           30|               24.0|            34020|     SAO PAULO|            SP|              BR|\n",
      "|8355199d-8a01-481...|2017-01-20 08:13:...|  false|          5|          81.0|          30|           15|               10.0|            45380|     SAO PAULO|            SP|              BR|\n",
      "|85f2e1f2-101b-4b7...|2017-01-20 08:15:...|  false|          1|          30.0|           0|           30|                0.0|            60541|     FORTALEZA|            CE|              BR|\n",
      "|889a435f-46f3-467...|2017-01-20 08:13:...|  false|          1|          30.0|           0|           40|                5.0|            20051|RIO DE JANEIRO|            RJ|              BR|\n",
      "|947cd11a-20c9-49f...|2017-01-20 08:14:...|  false|          2|          40.0|           0|           45|               15.0|            45630|     SAO PAULO|            SP|              BR|\n",
      "|97c713de-792e-47a...|2017-01-20 08:14:...|   true|          3|          80.0|           0|            0|               40.0|            91740|  PORTO ALEGRE|            RS|              BR|\n",
      "|a14150aa-1891-403...|2017-01-23 07:51:...|  false|          1|          30.0|           0|           80|               30.0|            56650|     SAO PAULO|            SP|              BR|\n",
      "|a25168e0-bbe4-487...|2017-01-20 08:14:...|   true|          3|          60.0|           0|           60|                0.0|            41515|      SALVADOR|            BA|              BR|\n",
      "|a87f72fd-c9da-4ab...|2017-01-23 07:38:...|  false|          3|          60.0|           0|           50|               10.0|            50830|     SAO PAULO|            SP|              BR|\n",
      "|b17782c4-d9c0-4ac...|2017-01-20 08:14:...|  false|          3|          60.0|           0|           50|               23.0|            88036| FLORIANOPOLIS|            SC|              BR|\n",
      "|b2332fc0-dc4c-475...|2017-01-23 07:50:...|  false|          1|          30.0|           0|           50|                0.0|            54220|     SAO PAULO|            SP|              BR|\n",
      "|ba52901e-dbf4-47c...|2017-01-20 08:15:...|   true|          4|          60.0|           0|            0|               33.0|            40310|      SALVADOR|            BA|              BR|\n",
      "|c1b9cae1-8473-480...|2017-01-20 08:15:...|  false|          2|          40.0|           0|           35|                0.0|            63102|   CARAPICUIBA|            SP|              BR|\n",
      "+--------------------+--------------------+-------+-----------+--------------+------------+-------------+-------------------+-----------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## restaurants data\n",
    "spark.sql('select * from restaurant limit 20').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|                  id|              string|   null|\n",
      "|          created_at|           timestamp|   null|\n",
      "|             enabled|             boolean|   null|\n",
      "|         price_range|                 int|   null|\n",
      "|      average_ticket|              double|   null|\n",
      "|        takeout_time|                 int|   null|\n",
      "|       delivery_time|                 int|   null|\n",
      "| minimum_order_value|              double|   null|\n",
      "|   merchant_zip_code|                 int|   null|\n",
      "|       merchant_city|              string|   null|\n",
      "|      merchant_state|              string|   null|\n",
      "|    merchant_country|              string|   null|\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|            Database|             default|       |\n",
      "|               Table|          restaurant|       |\n",
      "|               Owner|            santiago|       |\n",
      "|        Created Time|Mon Jan 10 22:23:...|       |\n",
      "|         Last Access|             UNKNOWN|       |\n",
      "|          Created By|         Spark 3.2.0|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## restaurants metadata\n",
    "spark.sql('describe formatted restaurant').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## restaurants data\n",
    "spark.sql('select * from restaurant limit 20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## consumers metadata\n",
    "spark.sql('describe formatted consumer').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## consumers data\n",
    "spark.sql('select * from consumer limit 20').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## orders metadata\n",
    "spark.sql('describe formatted order').show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## orders data\n",
    "\n",
    "spark.sql('select * from order limit 20').show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "770807fca9f82177f2182d3a969589be0e4df05a68ec7cea9b4d926677cead08"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
